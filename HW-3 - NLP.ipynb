{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IHgmxWG_7lnE"
   },
   "source": [
    "# Введение в анализ данных\n",
    "## НИУ ВШЭ, 2019-2020 учебный год\n",
    "\n",
    "### Домашнее задание №3\n",
    "\n",
    "Задание выполнил(а): Селиванова Валерия\n",
    "\n",
    "### Общая информация\n",
    "\n",
    "__Дата выдачи:__ 06.04.2020\n",
    "\n",
    "__Дедлайн:__ 23:59 20.04.2020\n",
    "\n",
    "\n",
    "### Оценивание и штрафы\n",
    "\n",
    "Оценка за ДЗ вычисляется по следующей формуле:\n",
    "\n",
    "$$\n",
    "min(\\text{points}, 18)  \\times 10 / 18,\n",
    "$$\n",
    "\n",
    "где points — количество баллов за обязательную часть, которое вы набрали. Максимальное число баллов, которое можно получить за обязательную часть — 18, за каждые полтора балла сверху вы получите 1 бонусный балл (максимум 2). Также вы можете использовать бонусные баллы, которые накопили ранее.\n",
    "\n",
    "За сдачу задания позже срока на итоговую оценку за задание накладывается штраф в размере 1 балл в день, но получить отрицательную оценку нельзя.\n",
    "\n",
    "__Внимание!__ Домашнее задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов.\n",
    "\n",
    "### Формат сдачи\n",
    "\n",
    "Загрузка файлов с решениями происходит в системе [Anytask](https://anytask.org/).\n",
    "\n",
    "Инвайт для группы ИАД-6: rd5CNrr\n",
    "\n",
    "Перед отправкой перезагрузите ноутбук и проверьте, что все ячейки могут быть последовательно выполнены. Ноутбук должен запускаться с использованием python 3.6+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ztx03xvr9T95"
   },
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BVrrwTJNjuDt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "colab_type": "code",
    "id": "_VMchexbjjTh",
    "outputId": "c1f66a1f-8851-42f3-e7e5-6c48d3c24707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: wget: command not found\r\n"
     ]
    }
   ],
   "source": [
    "# Качаем датасет\n",
    "\n",
    "!wget https://www.dropbox.com/s/tg55q9mrziroyrs/train_subset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rvXKae8q9nn-"
   },
   "source": [
    "### Данные\n",
    "\n",
    "Мы имеем дело с данными с торговой платформы Avito.\n",
    "Для каждого товара представлены следующие параметры:\n",
    " - title\n",
    " - description\n",
    " - Category_name\n",
    " - Category\n",
    "\n",
    "Имеется информация об объектах 50 классов.\n",
    "Задача: по новым объектам (title, description) предсказать Category.\n",
    "(Очевидно, что параметр Category_name для предсказания классов использовать нельзя)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "BqEuoDhqNgoa",
    "outputId": "b345f049-ae77-4d1b-a25f-4d4f447e63d2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>Category_name</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>382220</td>\n",
       "      <td>Прихожая</td>\n",
       "      <td>В хорошем состоянии. Торг</td>\n",
       "      <td>Мебель и интерьер</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397529</td>\n",
       "      <td>Кордиант 215/55/16 Летние</td>\n",
       "      <td>Кордиант 215/55/16 Летние/\\n /\\nАртикул: 1737l...</td>\n",
       "      <td>Запчасти и аксессуары</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>584569</td>\n",
       "      <td>Стол</td>\n",
       "      <td>Стол, 2 рабочих места . Стол серого цвета, в д...</td>\n",
       "      <td>Мебель и интерьер</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2513100</td>\n",
       "      <td>Комбинезон</td>\n",
       "      <td>Размер-42/44</td>\n",
       "      <td>Одежда, обувь, аксессуары</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1091886</td>\n",
       "      <td>Ветровка</td>\n",
       "      <td>На 2 года</td>\n",
       "      <td>Детская одежда и обувь</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title  \\\n",
       "id                                   \n",
       "382220                    Прихожая   \n",
       "397529   Кордиант 215/55/16 Летние   \n",
       "584569                        Стол   \n",
       "2513100                 Комбинезон   \n",
       "1091886                   Ветровка   \n",
       "\n",
       "                                               description  \\\n",
       "id                                                           \n",
       "382220                           В хорошем состоянии. Торг   \n",
       "397529   Кордиант 215/55/16 Летние/\\n /\\nАртикул: 1737l...   \n",
       "584569   Стол, 2 рабочих места . Стол серого цвета, в д...   \n",
       "2513100                                       Размер-42/44   \n",
       "1091886                                          На 2 года   \n",
       "\n",
       "                     Category_name  Category  \n",
       "id                                            \n",
       "382220           Мебель и интерьер        20  \n",
       "397529       Запчасти и аксессуары        10  \n",
       "584569           Мебель и интерьер        20  \n",
       "2513100  Одежда, обувь, аксессуары        27  \n",
       "1091886     Детская одежда и обувь        29  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train_subset.csv\", index_col='id')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Kg8iPp7fiwGh",
    "outputId": "96ed00ed-b63b-4478-f2d4-66bda1110b5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 4)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1hvzAMETU2d"
   },
   "outputs": [],
   "source": [
    "X = data[['title', 'description']].to_numpy()\n",
    "y = data['Category'].to_numpy()\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tMYU7zZw_cw-"
   },
   "source": [
    "Сразу разделим выборку на train и test.\n",
    "Никакие данные из test для обучения использовать нельзя!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6fia4_3vNprp"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "id": "qDR8LtTJUIGt",
    "outputId": "fd4d5b55-a023-4129-9ff5-a6e8e24db915"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Сапоги 46 размер новые', 'Сапоги 46 размер новые'],\n",
       "       ['Светильники потолочный swarovski',\n",
       "        'светильники потолочные swarovski 6 штук , цена за штуку. В эксплуатации 2 года , продаются в связи со сменой интерьера в квартире'],\n",
       "       ['iPhone 7 plus 128GB Red красный в наличии',\n",
       "        '\\xa0/\\n/\\n Данная цена только для подписчиков Instagram: iQmac/\\n/\\n Новый красный айфон 7 Plus в наличии это элегантный и мощный смартфон, который готов в полной мере раскрыть новые возможности iOS 10. Аппарат с 4-ядерным процессором А10 и 3 ГБ ОЗУ с легкостью решает самые ресурсоемкие задачи, позволяя наслаждаться быстродействием «тяжелых» приложений и игр на 5,5-дюймовом дисплее. Аппарат получил экран, как у iPad Pro, так что картинка теперь соответствует кинематографическому стандарту.'],\n",
       "       ['Пион Ирис Ромашка рассада',\n",
       "        'Пион куст 500 р ( более 10 шт)/\\nСаженец/ корень 100р/\\nРастут у нас более 70 лет/\\nРозовые, бордовые и белые/\\nНа фото цветы 2018г/\\nП. Зубчаниновка/\\nлибо пл. Революции/\\nЕсть ирисы, ромашка, клубника, боярышник и ирга'],\n",
       "       ['Кофта', 'Состояние отличное']], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 27,  20,  84, 106,  27])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X-ZEdlEGAXTD"
   },
   "source": [
    "### Токенизация (1 балл)\n",
    "\n",
    "\n",
    "Токенизация -- разбиение текста на мелкие части, которые можно обработать машинными методами.\n",
    "Можно использовать разные алгоритмы токенизации.\n",
    "Можете использовать WordPunctTokenizer или подобрать какой-то другой, если считаете, что он лучше подойдет для этой задачи.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: Здраствуйте. Я, Кирилл. Хотел бы чтобы вы сделали игру, 3Д-экшон суть такова...\n",
      "after: ['здраствуйте', '.', 'я', ',', 'кирилл', '.', 'хотел', 'бы', 'чтобы', 'вы', 'сделали', 'игру', ',', '3д', '-', 'экшон', 'суть', 'такова', '...']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "text = 'Здраствуйте. Я, Кирилл. Хотел бы чтобы вы сделали игру, 3Д-экшон суть такова...'\n",
    "\n",
    "print(\"before:\", text,)\n",
    "print(\"after:\", tokenizer.tokenize(text.lower()),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x_RYBKC26o1X"
   },
   "source": [
    "__Задание:__ реализуйте функцию ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "O9VgNlZ1Qy3o",
    "outputId": "59ef3a75-008e-47c5-fba8-a319eba13ef4"
   },
   "outputs": [],
   "source": [
    "def preprocess(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Данная функция принимает на вход текст, \n",
    "    а возвращает тот же текст, но с пробелами между каждым токеном\n",
    "    \"\"\"\n",
    "    a = tokenizer.tokenize (text.lower())\n",
    "    b = ' '.join (a)\n",
    "    \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert preprocess(text) == 'здраствуйте . я , кирилл . хотел бы чтобы вы сделали игру , 3д - экшон суть такова ...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ токенизируйте title и description в train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z5WO-7tJUvbs"
   },
   "outputs": [],
   "source": [
    "X_train = np.array ([[preprocess (title), preprocess (description)] for title, \n",
    "                     description in X_train])\n",
    "X_test = np.array ([[preprocess (title), preprocess (description)]for title, \n",
    "                    description in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VDnDSWwFDwFo"
   },
   "outputs": [],
   "source": [
    "assert X_train[10][1] == 'продам иж планета 3 , 76 год , ( стоит на старом учёте , документы утеряны ) на ходу , хорошее состояние , все интересующие вопросы по телефону ( с родной коляской на 3 тысячи дороже ) . торга не будет .'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hlIITUk0AsmS"
   },
   "source": [
    "### BOW (3 балла)\n",
    "\n",
    "Один из традиционных подходов -- построение bag of words.\n",
    "\n",
    "Метод состоит в следующем:\n",
    "\n",
    " - Составить словарь самых часто встречающихся слов в train data\n",
    " - Для каждого примера из train посчитать, сколько раз каждое слово из словаря в нём встречается\n",
    "\n",
    "\n",
    " В sklearn есть CountVectorizer, но в этом задании его использовать нельзя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GMKUttDWIF92"
   },
   "source": [
    "__Задание:__ создайте словарь, где в соответствии каждому токену стоит количество раз, которое оно встретилось в X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "a = np.concatenate (X_train, axis = None)\n",
    "b = map (str, np.concatenate ([i.split() for i in a], axis = None))\n",
    "\n",
    "tokens = Counter (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tokens['сапоги'] == 454"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ выведите 10 самых частотных и 10 самых редких токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/', ',', '.', '-', 'в', 'и', 'на', './', ':', 'с']\n",
      "['iqmac', 'ядерным', 'ресурсоемкие', 'быстродействием', 'кинематографическому', 'ирис', 'саженец', 'корень', 'зубчаниновка', 'боярышник']\n"
     ]
    }
   ],
   "source": [
    "c = sorted (tokens.items(), key = lambda item: -item [1]) #частотные\n",
    "print ([k for k, v in c][:10])\n",
    "d = sorted (tokens.items(), key = lambda item: item [1]) #редкие\n",
    "print ([k for k, v in d][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ оставьте в словаре только топ 10000 самых частотных токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = {k: v for k, v in c [:10000]}\n",
    "tokens1 = list (tokens.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ реализуйте функцию, которая предложение переводит в вектор из чисел. То есть каждому слову из словаря сопоставляется количество раз, которое оно встретилось в предложении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4awkhecbR9om"
   },
   "outputs": [],
   "source": [
    "def text_to_bow(text: str, tokens1: list) -> np.array:\n",
    "    \"\"\"\n",
    "    Возвращает вектор, где для каждого слова из most_common\n",
    "    указано количество его употреблений\n",
    "    input: строка\n",
    "    output: вектор размерности словаря\n",
    "    \"\"\"\n",
    "    \n",
    "    a = text.split()\n",
    "    b = dict (Counter (a))\n",
    "    c = np.array ([b.get (i, 0) for i in tokens1])\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ а теперь реализуйте функцию, которая преобразует наш датасет и для каждого текста из description сопоставляет вектор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HR_D8Fn4pudv"
   },
   "outputs": [],
   "source": [
    "def items_to_bow(items: np.array) -> np.array:\n",
    "    \"\"\" Для каждого товара возвращает вектор его bow \"\"\"\n",
    "    \n",
    "    des = items [:, 1]\n",
    "    a = np.array ([text_to_bow (i, tokens1) for i in des])\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "wwOZaEpMSQsZ",
    "outputId": "8a30c3af-3517-42bd-a5f3-36206b4b264a"
   },
   "outputs": [],
   "source": [
    "X_train_bow = items_to_bow(X_train)\n",
    "X_test_bow = items_to_bow(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 13966.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# чтобы видеть проход по итерациям можно использовать библиотеку tqdm\n",
    "# она работает примерно так\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJVLS8Fs3CeT"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vJoXiCWI7VF5"
   },
   "source": [
    "### Логистическая регрессия и SVC (0.5 балла)\n",
    "\n",
    "\n",
    "Теперь описание каждого товара представлено, как точка в многомерном пространстве.\n",
    "Очень важно запомнить эту идею: дальше мы будем рассматривать разные способы перехода от текста к точке в пространстве.\n",
    "\n",
    "Для BOW каждое измерение в пространстве -- какое-то слово.\n",
    "Мы предполагаем, что текст описывается набором каких-то популярных слов, которые в нём встречаются, а близкие по смыслу тексты будут использовать одинаковые слова.\n",
    "\n",
    "Обучите логистическую регрессию и SVC с базовыми параметрами.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "Ky3HV1rTSS9L",
    "outputId": "612a5f0d-76bd-44f4-eeeb-63b517443797"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valeria/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/valeria/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7046666666666667\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X_train_bow1 = csr_matrix (X_train_bow)\n",
    "lr_model = LogisticRegression (random_state = 42, max_iter = 500)\n",
    "lr_model.fit (X_train_bow1, y_train)\n",
    "ypr = lr_model.predict (X_test_bow)\n",
    "print('Accuracy: {}'.format (accuracy_score (y_test, ypr)))\n",
    "\n",
    "assert accuracy_score(lr_model.predict(X_test_bow), y_test) > 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "-c46ZT0lvF6T",
    "outputId": "4b1cb34a-201b-4dc2-9155-fdb6919c6c08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6842222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc_model = LinearSVC (random_state = 42, max_iter = 10000)\n",
    "svc_model.fit (X_train_bow1, y_train)\n",
    "ypr = svc_model.predict (X_test_bow)\n",
    "print('Accuracy: {}'.format (accuracy_score (y_test, ypr)))\n",
    "\n",
    "assert accuracy_score(svc_model.predict(X_test_bow), y_test) > 0.68"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WwKE57YZ1Hzn"
   },
   "source": [
    "### Модификация признаков (0.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ewMlxQezL6Ax"
   },
   "source": [
    "Добавьте title товара в bow с произвольным весом, как изменится качество?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "evqKo1r5L5BO"
   },
   "outputs": [],
   "source": [
    "def title (items: np.array, tokens1:list) -> np.array:\n",
    "    a = items [:, 0]\n",
    "    b = np.array ([text_to_bow (i, tokens1) for i in a])\n",
    "    return b\n",
    "X_train_bow2 = X_train_bow + title (X_train, tokens1)\n",
    "X_test_bow2 = X_test_bow + title (X_test, tokens1)\n",
    "X_train_bow3 = csr_matrix (X_train_bow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valeria/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/valeria/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7837777777777778\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression (random_state = 42, max_iter = 500)\n",
    "lr_model.fit (X_train_bow3, y_train)\n",
    "ypr = lr_model.predict (X_test_bow2)\n",
    "print ('Accuracy: {}'.format (accuracy_score (y_test, ypr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valeria/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7535555555555555\n"
     ]
    }
   ],
   "source": [
    "svc_model = LinearSVC (random_state = 42, max_iter = 10000)\n",
    "svc_model.fit (X_train_bow3, y_train)\n",
    "ypr = svc_model.predict (X_test_bow2)\n",
    "print ('Accuracy: {}'.format (accuracy_score (y_test, ypr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Для обоих моделей качество повысилось__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Db4TyqzxMnby"
   },
   "source": [
    "Нормализуйте данные (`sklearn.preprocessing.normalize`) перед обучением. Что станет с качеством и почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A8rVy6q1Mn4J"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "X_train_bow4 = sklearn.preprocessing.normalize (X_train_bow1)\n",
    "X_test_bow3 = sklearn.preprocessing.normalize (X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valeria/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/valeria/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression (random_state = 42, max_iter = 500)\n",
    "lr_model.fit (X_train_bow4, y_train)\n",
    "ypr = lr_model.predict (X_test_bow3)\n",
    "print ('Accuracy: {}'.format (accuracy_score (y_test, ypr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7244444444444444\n"
     ]
    }
   ],
   "source": [
    "svc_model = LinearSVC (random_state = 42, max_iter = 10000)\n",
    "svc_model.fit (X_train_bow4, y_train)\n",
    "ypr = svc_model.predict (X_test_bow3)\n",
    "print ('Accuracy: {}'.format (accuracy_score (y_test, ypr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество для обеих моделей ухудшилось. Это связано с тем, что нормализация существенно не меняет данные. Не изменяются веса отдельных слов, расстояния между текстами и т. д., поэтому качество модели и не улучшается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HvCAL3qGDByj"
   },
   "source": [
    "### Mystem (1 балл)\n",
    "\n",
    "Попробуйте обучиться, используя токенизатор mystem. Сравните качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hz38TqqRDY6-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: wget: command not found\n",
      "tar: Error opening archive: Failed to open 'mystem-3.0-linux3.1-64bit.tar.gz'\n",
      "cp: mystem: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!wget http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
    "!tar -xvf mystem-3.0-linux3.1-64bit.tar.gz\n",
    "!cp mystem /bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "60oQ-6UgDcLF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/nlpub/pymystem3\n",
      "  Cloning https://github.com/nlpub/pymystem3 to /private/var/folders/td/jfnkrcjn0h94yj1jkppgbvzh0000gn/T/pip-req-build-9q2v09ns\n",
      "  Running command git clone -q https://github.com/nlpub/pymystem3 /private/var/folders/td/jfnkrcjn0h94yj1jkppgbvzh0000gn/T/pip-req-build-9q2v09ns\n",
      "Requirement already satisfied: requests in ./opt/anaconda3/lib/python3.7/site-packages (from pymystem3==0.2.0) (2.22.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.7/site-packages (from requests->pymystem3==0.2.0) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in ./opt/anaconda3/lib/python3.7/site-packages (from requests->pymystem3==0.2.0) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./opt/anaconda3/lib/python3.7/site-packages (from requests->pymystem3==0.2.0) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./opt/anaconda3/lib/python3.7/site-packages (from requests->pymystem3==0.2.0) (3.0.4)\n",
      "Building wheels for collected packages: pymystem3\n",
      "  Building wheel for pymystem3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pymystem3: filename=pymystem3-0.2.0-cp37-none-any.whl size=9922 sha256=1ced844cb818963df1b3876cdde1cb3f651cc264d20b8a6f99b70c74193721cf\n",
      "  Stored in directory: /private/var/folders/td/jfnkrcjn0h94yj1jkppgbvzh0000gn/T/pip-ephem-wheel-cache-p8t3bgce/wheels/7d/75/c2/216a594291dee680749ce12c60d16125cfe1f363059e7163dc\n",
      "Successfully built pymystem3\n",
      "Installing collected packages: pymystem3\n",
      "Successfully installed pymystem3-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/nlpub/pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mGvNHfVsDfhq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing mystem to /Users/valeria/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-macosx.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from pymystem3 import Mystem\n",
    "mystem = Mystem (entire_input = False)\n",
    "X_trainl = [[mystem.lemmatize (t), mystem.lemmatize (d)] for t, d in X_train]\n",
    "X_testl = [[mystem.lemmatize (t), mystem.lemmatize (d)] for t, d in X_test]\n",
    "X_trainl = [' '.join (np.concatenate (z)) for z in X_trainl]\n",
    "X_testl = [' '.join (np.concatenate (z)) for z in X_testl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/valeria/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "thenword = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "N = CountVectorizer (stop_words = thenword)\n",
    "X_trainl1 = N.fit_transform (X_trainl)\n",
    "X_testl1 = N.transform (X_testl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valeria/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/valeria/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7972222222222223\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression (random_state = 42, max_iter = 500)\n",
    "lr_model.fit (X_trainl1, y_train)\n",
    "ypr = lr_model.predict (X_testl1)\n",
    "print ('Accuracy: {}'.format (accuracy_score (y_test, ypr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7841111111111111\n"
     ]
    }
   ],
   "source": [
    "svc_model = LinearSVC (random_state = 42, max_iter = 10000)\n",
    "svc_model.fit (X_trainl1, y_train)\n",
    "ypr = svc_model.predict (X_testl1)\n",
    "print ('Accuracy: {}'.format (accuracy_score (y_test, ypr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество для обоих моделей увеличилось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bXbsPtpfoB7m"
   },
   "source": [
    "### TF-IDF (5 баллов)\n",
    "\n",
    "Не все слова полезны одинаково, давайте попробуем [взвесить](http://tfidf.com/) их, чтобы отобрать более полезные.\n",
    "\n",
    "\n",
    "> TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
    "> \n",
    "> IDF(t) = log_e(Total number of documents / Number of documents with term t in it).\n",
    "\n",
    "\n",
    "В sklearn есть TfidfVectorizer, но в этом задании его использовать нельзя. Для простоты посчитайте общий tf-idf для title и description (то есть каждому объекту надо сопоставить вектор, где как документ будет рассматриваться конкатенация title и description)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ составьте словарь, где каждому слову из изначального словаря будет стоять в соответствии количество документов, где это слово встретилось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3a9fcc196e4a778e8487093e3264a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "doc = map (' '.join, X_train)\n",
    "w = [i.split() for i in doc]\n",
    "def dcnt (word: str):\n",
    "    a = sum ([word in b for b in w])\n",
    "    return a\n",
    "dic = {word : dcnt (word) for word in tqdm (tokens1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ реализуйте функцию, где тексту в соответствие ставится tf-idf вектор. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6i5zFpD9rbtz"
   },
   "outputs": [],
   "source": [
    "n = len (X_train)\n",
    "def text_to_tfidf(text: str, dic: dict, tokens1: list, n: int) -> np.array:\n",
    "    \"\"\"\n",
    "    Возвращает вектор, где для каждого слова из словаря\n",
    "    указан tf-idf\n",
    "    \"\"\"\n",
    "    \n",
    "    a = text_to_bow (text, tokens1)\n",
    "    b = len (text.split())\n",
    "    c = [(a [i] / b) * np.log (n / dic [word]) for i, word in enumerate (tokens1)]\n",
    "    d = np.array (c)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ а теперь реализуйте функцию, которая преобразует наш датасет и для каждого объекта сопоставляет вектор tf-idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def items_to_tfidf(items: np.array) -> np.array:\n",
    "    \"\"\" \n",
    "    Для каждого товара возвращает его tfidf вектор\n",
    "    \"\"\"\n",
    "    a = [text_to_tfidf (t + ' ' + d, dic, tokens1, n) for t, d in tqdm (items)]\n",
    "    b = np.array (a)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96bcd5a278742a59aaf7943ae61f794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742503e427544d7b9ed2dc9c0757b46f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_tfidf = items_to_tfidf(X_train)\n",
    "X_test_tfidf = items_to_tfidf(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-YFA-8kE1RHk"
   },
   "source": [
    "__Задание:__ обучите логистическую регрессию и SVC, оцените качество (accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ULrXsF1m5sU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6628888888888889\n"
     ]
    }
   ],
   "source": [
    "X_train_tfidf1 = csr_matrix (X_train_tfidf)\n",
    "lr_model = LogisticRegression (random_state = 42, max_iter = 500)\n",
    "lr_model.fit (X_train_tfidf1, y_train)\n",
    "ypr = lr_model.predict (X_test_tfidf)\n",
    "print ('Accuracy: {}'.format (accuracy_score (y_test, ypr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7942222222222223\n"
     ]
    }
   ],
   "source": [
    "svc_model = LinearSVC (random_state = 42, max_iter = 10000)\n",
    "svc_model.fit (X_train_tfidf1, y_train)\n",
    "ypr = svc_model.predict (X_test_tfidf)\n",
    "print ('Accuracy: {}'.format (accuracy_score (y_test, ypr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество логистической регрессии снизилось, а SVC модели увеличилось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jFdy3lUFDsOr"
   },
   "source": [
    "### Hashing Vectorizer (1 балл)\n",
    "\n",
    "Попробуйте использовать `sklearn.feature_extraction.text.HashingVectorizer` для векторизации текстов.\n",
    "Обязательно оцените качество работы алгоритмов классификации с использованием новой векторизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y666HTrqDq1m"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/valeria/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "import nltk\n",
    "nltk.download ('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = HashingVectorizer (tokenizer = nltk.tokenize.word_tokenize, analyzer = 'word')\n",
    "X_trainv = vectorizer.fit_transform ([i [0] + ' ' + i [1] for i in X_train])\n",
    "X_testv = vectorizer.fit_transform ([i [0] + ' ' + i [1] for i in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valeria/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6503333333333333\n"
     ]
    }
   ],
   "source": [
    "X_trainv1 = csr_matrix (X_trainv)\n",
    "lr_model = LogisticRegression (random_state = 42, max_iter = 500)\n",
    "lr_model.fit (X_trainv1, y_train)\n",
    "ypr = lr_model.predict (X_testv)\n",
    "print ('Accuracy: {}'.format (accuracy_score (y_test, ypr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8106666666666666\n"
     ]
    }
   ],
   "source": [
    "svc_model = LinearSVC (random_state = 42, max_iter = 10000)\n",
    "svc_model.fit (X_trainv1, y_train)\n",
    "ypr = svc_model.predict (X_testv)\n",
    "print ('Accuracy: {}'.format (accuracy_score (y_test, ypr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vQZ61xSsTpZI"
   },
   "source": [
    "### Word Vectors (3 балла)\n",
    "\n",
    "Давайте попробуем другой подход -- кажому слову сопоставим какой-то эмбеддинг (вектор).\n",
    "\n",
    "Вектора будут небольшой размерности. Таким образом мы снизим количество параметров в модели.\n",
    "\n",
    "Вектора мы возьмём уже готовые (обученные на текстах их интернета), так что наша модель будет знать некоторую дополнительную информацию о внешнем мире."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "colab_type": "code",
    "id": "T38J27NcYGx5",
    "outputId": "57fa3a9f-13a3-4fa1-d13c-3c0c49a86a71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: wget: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/0x7oxso6x93efzj/ru.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zfse4xVbgMIr",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tar -xzf ru.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in ./opt/anaconda3/lib/python3.7/site-packages (3.8.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in ./opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.11.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in ./opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.17.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in ./opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5.0 in ./opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: boto in ./opt/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: boto3 in ./opt/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.12.41)\n",
      "Requirement already satisfied: requests in ./opt/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.41 in ./opt/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.15.41)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in ./opt/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in ./opt/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.5)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in ./opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.9.11)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in ./opt/anaconda3/lib/python3.7/site-packages (from botocore<1.16.0,>=1.15.41->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in ./opt/anaconda3/lib/python3.7/site-packages (from botocore<1.16.0,>=1.15.41->boto3->smart-open>=1.8.1->gensim) (2.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sy2TXmQ2jZSY"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.wrappers import FastText\n",
    "\n",
    "model = FastText.load_fasttext_format('ru.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "[ 0.02916384  0.02167605  0.05127367 -0.00971958  0.0465235  -0.03945766\n",
      "  0.02737866  0.00638128 -0.03774629 -0.04257201 -0.00995653  0.02291315\n",
      " -0.02301722  0.06697998 -0.03674482 -0.02403202 -0.05404469  0.01372932\n",
      "  0.00926399 -0.0013149   0.11941359 -0.022448    0.04011497  0.06980549\n",
      "  0.00407011 -0.09384539  0.03050164 -0.02578281 -0.03525181 -0.06603175\n",
      "  0.04752798  0.05874675  0.01983666  0.06092105 -0.00957561  0.08307806\n",
      " -0.01288903  0.04705157  0.02198839 -0.00649013 -0.0171444   0.03302203\n",
      "  0.02124882 -0.01902875 -0.05235172  0.03458685 -0.01409259 -0.07477519\n",
      "  0.01916078  0.02985001  0.0086322   0.03051201  0.02831862  0.04549561\n",
      "  0.00761138 -0.05459622  0.09056009 -0.08807947 -0.05420396 -0.04793203\n",
      " -0.05672329 -0.03025264 -0.03024072 -0.05890108 -0.03137474  0.03292617\n",
      "  0.05440779 -0.04548327 -0.07266086 -0.09327219  0.07247883  0.0111061\n",
      "  0.01824225 -0.10570452  0.05110046 -0.04659343 -0.03277056 -0.00803401\n",
      " -0.03978698  0.00826598 -0.01074128  0.018431   -0.10150263 -0.00472604\n",
      "  0.06706332  0.02466901  0.09045192 -0.05226929  0.04866098 -0.02843297\n",
      "  0.04756537  0.00261342  0.06845197  0.00082511 -0.00547984  0.0100649\n",
      "  0.02135489 -0.01437242  0.00191435  0.11989547  0.02357679  0.07061605\n",
      "  0.03375214  0.05462346  0.08270866  0.00126649  0.03054527  0.04314573\n",
      " -0.00719835 -0.02799017  0.00249404  0.00139046 -0.04099929  0.00526204\n",
      "  0.01386764  0.02106066  0.00887202  0.05943111 -0.07185322  0.03263306\n",
      "  0.00284878  0.03816929  0.0210096  -0.030828    0.00502779  0.09250114\n",
      "  0.02399154  0.05744717 -0.04319151  0.04075926 -0.03877947  0.0605263\n",
      " -0.00837917 -0.04922852 -0.04570796  0.02973622 -0.01798053  0.00413011\n",
      " -0.00712464 -0.01312802  0.05847022 -0.07881333 -0.02204878  0.03086594\n",
      "  0.02965177 -0.0073295  -0.02443145 -0.06222062  0.01083152  0.06009534\n",
      " -0.02042049  0.06301811  0.02287635 -0.03021961  0.04831248  0.02882019\n",
      "  0.04446645 -0.01677353 -0.08272323 -0.06830658  0.08947854  0.03370909\n",
      " -0.00895046 -0.00681254 -0.02059644 -0.09527113  0.02611189 -0.06112244\n",
      "  0.01080315  0.01901113  0.00810233  0.00742132  0.10493557 -0.00522375\n",
      "  0.05826566  0.03236291  0.03787734 -0.05026894 -0.08401242  0.02860721\n",
      " -0.05106218  0.02631241  0.02631763  0.06924202  0.03319636  0.00980412\n",
      "  0.04016861  0.03428936  0.00652957 -0.01058654 -0.0245588   0.1464914\n",
      " -0.01041028  0.03553488 -0.07482928 -0.01063148 -0.0342233  -0.01662586\n",
      " -0.00029508  0.04694034 -0.00062491 -0.0435293  -0.01315623  0.07061336\n",
      "  0.01603698  0.02374655  0.05453315  0.00253603 -0.0313729  -0.02740866\n",
      "  0.04278845 -0.00810288  0.03973977  0.07674816  0.04658518 -0.02685211\n",
      " -0.05009724  0.0060723  -0.04231661  0.02584185 -0.03419575 -0.03799306\n",
      "  0.06701688 -0.1245426   0.03846397 -0.0855662  -0.01193651  0.04968415\n",
      "  0.03559558  0.10029506  0.05714916  0.01145345 -0.03564315 -0.00924199\n",
      "  0.08630151  0.08049053  0.05822275 -0.05224873 -0.02462301  0.05832206\n",
      " -0.04124978  0.00186134  0.00782246  0.01179015 -0.02291097  0.00614069\n",
      "  0.01782681  0.02190027  0.04341367  0.06151633 -0.01183114 -0.00141502\n",
      "  0.06193598  0.0611085  -0.02373199 -0.05797793 -0.02269631  0.11511736\n",
      " -0.04581353 -0.05082048 -0.04706197  0.0429772   0.00409648 -0.0141248\n",
      "  0.01417164  0.00575812 -0.07616108 -0.01051838  0.05149659  0.02367133\n",
      "  0.00073724  0.05957585 -0.11871962  0.03876314  0.03472188 -0.02344368\n",
      " -0.01165281 -0.01397923  0.08815268  0.03459521  0.07113555 -0.03984846\n",
      " -0.01600395  0.01932258  0.01351069 -0.06409036 -0.02024848  0.05895981\n",
      "  0.02591374 -0.04027611  0.00654722  0.05093394 -0.02461737  0.02561689\n",
      " -0.01412898 -0.00366109 -0.06719207  0.00742674 -0.02095614 -0.06263787]\n"
     ]
    }
   ],
   "source": [
    "# как мы видим, каждому словву данная модель сопоставляет вектор размерности 300\n",
    "\n",
    "print(model['привет'].shape)\n",
    "print(model['привет'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H49QR_jhjmCa"
   },
   "outputs": [],
   "source": [
    "# Будем рассматривать эмбеддинг предложения, как сумму эмбеддингов токенов\n",
    "\n",
    "def sentence_embedding(sentence: str, model) -> np.array:\n",
    "    \"\"\"\n",
    "    Складывает вектора токенов строки sentence\n",
    "    \"\"\"\n",
    "    \n",
    "    a = sentence.split ()\n",
    "    b = np.array ([model [i] for i in a if i in model.wv])\n",
    "    c = np.sum (b, axis = 0)\n",
    "    if c.shape == (300, ):\n",
    "        return c\n",
    "    else:\n",
    "        return np.zeros ((300, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gj6U_hjtlllV"
   },
   "outputs": [],
   "source": [
    "assert np.allclose(sentence_embedding('сдаётся уютный , тёплый гараж для стартапов в ml', model)[::50],\n",
    "                   np.array([ 0.08189847,  0.07249198, -0.15601222,  0.03782297,  0.09215296, -0.23092946]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ сделайте все то же, что в предыдущих пунктах -- реализуйте функцию, которая преобразует данные, а затем обучите логистическую регрессию и SVM, оцените качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8tfhc-PFmGvu"
   },
   "outputs": [],
   "source": [
    "def embd (items: np.array, model) -> np.array:\n",
    "    a = [sentence_embedding (t + ' ' + d, model) for t, d in tqdm (items)]\n",
    "    b = np.array (a)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69181a359b04c2794cf8678435902d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95854d313c424ffa9df6d61d07dc024f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_trainem = embd (X_train, model)\n",
    "X_testem = embd (X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valeria/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/valeria/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5781111111111111\n"
     ]
    }
   ],
   "source": [
    "X_trainem1 = csr_matrix (X_trainem)\n",
    "lr_model = LogisticRegression (random_state = 42, max_iter = 500)\n",
    "lr_model.fit (X_trainem1, y_train)\n",
    "ypr = lr_model.predict (X_testem)\n",
    "print ('Accuracy: {}'.format (accuracy_score (y_test, ypr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valeria/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5712222222222222\n"
     ]
    }
   ],
   "source": [
    "svc_model = LinearSVC (random_state = 42, max_iter = 10000)\n",
    "svc_model.fit (X_trainem1, y_train)\n",
    "ypr = svc_model.predict (X_testem)\n",
    "print ('Accuracy: {}'.format (accuracy_score (y_test, ypr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cVEdlFostSnX"
   },
   "source": [
    "### Что дальше? (6 баллов)\n",
    "\n",
    "Для получения максимальной оценки вам нужно решить любые 2 пункта. Решение каждого пункта даст вам полтора балла:\n",
    "\n",
    "1. Реализовать N-Gram модели текстовой классификации (__1.5 балла__)\n",
    "\n",
    "2. Поработать с другими эмбеддингами для слов (например word2vec или GloVe) (__1.5 балла__)\n",
    "\n",
    "3. Другие способы токенизации (pymorphy2, spaCy) (__1.5 балла__)\n",
    "\n",
    "4. Добиться качества > 0.765 на тестовых данных (попробуйте другие токенизаторы, предобработку текста, и любые другие идеи, которые вам придут в голову) (__1.5 балла__)\n",
    "\n",
    "Снабжайте код пояснениями и графиками.\n",
    "Обязательно необходимо написать вывод по каждому пункту, который вы реализуете."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Пункт 1__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем `N-Gram` модели через `SciKitLearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = CountVectorizer (stop_words = thenword, ngram_range = (1, 5))\n",
    "X_trainn = ngram.fit_transform (X_trainl)\n",
    "X_testn = ngram.transform (X_testl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valeria/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/valeria/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7718888888888888\n"
     ]
    }
   ],
   "source": [
    "X_trainem1 = csr_matrix (X_trainem)\n",
    "lr_model = LogisticRegression (random_state = 42, max_iter = 500)\n",
    "lr_model.fit (X_trainn, y_train)\n",
    "ypr = lr_model.predict (X_testn)\n",
    "print ('Accuracy: {}'.format (accuracy_score (y_test, ypr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7764444444444445\n"
     ]
    }
   ],
   "source": [
    "svc_model = LinearSVC (random_state = 42, max_iter = 10000)\n",
    "svc_model.fit (X_trainn, y_train)\n",
    "ypr = svc_model.predict (X_testn)\n",
    "print ('Accuracy: {}'.format (accuracy_score (y_test, ypr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество моделей изменилось немного снизилось по сравнению с использованием униграмм в майстеме (было 0.797 для логистической регрессии и 0.784 для опорных векторов). Это может быть связано с тем, что для наших целей на наших данных важнее отдельные слова, а не их сочетания, т. к. поиск товаров обычно осуществляется как раз по ключевым словам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Пункт 4__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество > 0.765 уже было достигнуто при использовании некоторых методов ранее.\n",
    "\n",
    "При использовании `MyStem` (0.797 для логистической регрессии и 0.784 для SVC), `хэшинга` (0.81 для опорных векторов) и `n-gram` модели."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
